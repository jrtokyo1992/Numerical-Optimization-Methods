{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Preparations\n",
    "http://www.turbare.net/transl/scipy-lecture-notes/advanced/mathematical_optimization/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "epsilon = 0.00005\n",
    "def get_dev(func, x,i): # Be sure to use float type array\n",
    "    x_new = x.copy()\n",
    "    x_new[i] = x_new[i]+epsilon\n",
    "    return (func(x_new)-func(x))/epsilon\n",
    "\n",
    "def get_dev_2nd(func, x,i,j):\n",
    "    if (i !=j):\n",
    "        x_new_ij, x_new_i,x_new_j = x.copy(),x.copy(),x.copy()\n",
    "        x_new_ij[i],x_new_ij[j],x_new_i[i], x_new_j[j]= x[i]+epsilon,x[j]+epsilon,x[i]+epsilon,x[j]+epsilon\n",
    "        results = (func(x_new_ij)+func(x)-func(x_new_i)-func(x_new_j))/(epsilon**2)\n",
    "    else:\n",
    "        x_new_plus, x_new_minus = x.copy(), x.copy()\n",
    "        x_new_plus[i] = x[i]+epsilon\n",
    "        x_new_minus[i] = x[i] - epsilon\n",
    "        results = (func(x_new_plus)+func(x_new_minus)-2*func(x))/(epsilon**2)\n",
    "        \n",
    "    return results\n",
    "\n",
    "# example function\n",
    "from functools import reduce\n",
    "def calc1(numbers):\n",
    "    return sum ([ (n-1)**2 for n in numbers   ])\n",
    "\n",
    "def calc2(numbers):\n",
    "    return reduce(lambda a, b: a**0.5*b, numbers)\n",
    "\n",
    "def calc3(numbers):\n",
    "    x,y,z= numbers[0],numbers[1],numbers[2]\n",
    "    return (x-1)**2 + (y+5)**2 + (z-2)**2 + x*y*z\n",
    "\n",
    "def calc4(numbers):\n",
    "    x,y,z= numbers[0],numbers[1],numbers[2]\n",
    "    return -(x-1)**2 -(y+5)**2 - x*z*y - (z-2)**2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepest Descent Method\n",
    "Set the gradient as the direction when exploring the local miminal point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddm(func, x):\n",
    "    adjust = 0.15\n",
    "    x_iter=x\n",
    "    n_var = len(x)\n",
    "    iter_time = 1\n",
    "    while ( 1 ):\n",
    "        jacob = [get_dev(func , x_iter, i) for i in range(0,n_var)]\n",
    "        x_iter_new = list (  map (lambda a, b: a-b*adjust, x_iter,jacob ) )\n",
    "        iter_time = iter_time + 1\n",
    "        error = sum( list ( map (lambda a, b: (a-b)**2, x_iter_new, x_iter ) ) )\n",
    "        #print(jacob, error)\n",
    "        if (error<0.00000005 or iter_time >500):\n",
    "            break\n",
    "        x_iter = x_iter_new\n",
    "    return x_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9998841403886821, 1.0000182472506487, 0.9990794992168831]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddm (calc,[2,3,-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newton method\n",
    "Deep Descent use first-order derivative as the direction, which may lead to a low speed of convergence. Newton method considers second-order derivatives, therefore it has a higher speed of convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(func, x):\n",
    "    n = len(x)\n",
    "    adjust = 0.15\n",
    "    x_iter = x\n",
    "    iter_time = 1\n",
    "    while(1):\n",
    "        jacob =np.array([ get_dev(func, x_iter,i) for i in range(0,n) ] ).T\n",
    "        hes_list = [ get_dev_2nd(func, x_iter,i,j) for i in range(0,n) for j in range(0,n)]\n",
    "        d = np.dot(inv(np.array(hes_list).reshape(n,n)),jacob).tolist()\n",
    "        x_iter_new = list (  map (lambda a, b: a-b*adjust, x_iter,d ) )\n",
    "        iter_time = iter_time + 1\n",
    "        error = sum( list ( map (lambda a, b: (a-b)**2, x_iter_new, x_iter ) ) )\n",
    "        #print(x_iter, error)\n",
    "        if (error<0.000000005 or iter_time >500):\n",
    "            break\n",
    "        x_iter = x_iter_new\n",
    "    return x_iter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.9531665028331084, 1.7334606340700551, 4.560039136918094]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newton(calc3, [2.0,3.0,4.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quasi-Newton Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quasi_newton(func, x, alpha = 0.05, max_iter =500, tol = 1e-5):\n",
    "    # let alpha as small as possible !!!\n",
    "    n = len(x)\n",
    "    x_iter = x\n",
    "    iter_time = 1\n",
    "    B = np.eye(n)\n",
    "    while(1):\n",
    "        # currently, x_iter is list\n",
    "        jacob =np.matrix([get_dev(func, x_iter,i) for i in range(0,n)]).T\n",
    "        d = - np.dot(inv(B),jacob)\n",
    "        # Turn the x_iter into a matrix\n",
    "        x_iter = np.matrix(x_iter).T\n",
    "        x_iter_new = x_iter + alpha * d\n",
    "        iter_time = iter_time + 1\n",
    "        error = np.linalg.norm (x_iter_new- x_iter )\n",
    "        if (error< tol or iter_time >max_iter):\n",
    "            break\n",
    "        # Now calculate the new B\n",
    "        s = x_iter_new - x_iter\n",
    "        # Turn the x_iter_new back into list\n",
    "        x_iter_new = [ x_iter_new.item(i) for i in range(0,n)]\n",
    "        jacob_new = np.matrix([ get_dev(func, x_iter_new,i) for i in range(0,n) ] ).T\n",
    "        y = jacob_new - jacob\n",
    "        B = B-np.dot(np.dot(B,s), np.dot(B,s).T)/np.dot( np.dot(s.T,B),s )+np.dot(  y ,  y.T)/(np.dot(s.T,y))\n",
    "       \n",
    "        x_iter = x_iter_new\n",
    "    \n",
    "    x_iter = np.array(x_iter)\n",
    "    x_iter = [ x_iter[i][0] for i in range(0,n)]\n",
    "    return x_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.9531309635034315, 1.7337718808721017, 4.560130926161302]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quasi_newton(calc3 ,[2.0,3.0,4.0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
